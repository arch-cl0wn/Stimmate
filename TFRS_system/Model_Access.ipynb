{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af6f53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Text\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "from tensorflow.keras import Sequential, regularizers\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Flatten, Reshape, Concatenate,BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup, Normalization, TextVectorization\n",
    "\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f2e80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders=['Non-binary', 'Female', 'Prefer not to say', 'Male']\n",
    "sexuality=['Lesbian', 'Straight', 'Queer', 'Bisexual', 'Asexual', 'Pansexual','Gay', 'Demisexual', 'Heterosexual', 'Homosexual']\n",
    "\n",
    "class WeightClip(Constraint):\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    def __call__(self, w):\n",
    "        return tf.clip_by_value(w, -self.clip_value, self.clip_value)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}\n",
    "\n",
    "# Preprocessing layers\n",
    "gender_lookup = StringLookup()\n",
    "gender_lookup.adapt(genders)\n",
    "sexuality_lookup = StringLookup()\n",
    "sexuality_lookup.adapt(sexuality)\n",
    "age_normalizer = Normalization()\n",
    "score_normalizer = Normalization()\n",
    "# TextVectorization layer for stim names\n",
    "max_tokens = 2000  # Maximum number of unique tokens, adjust this value according to your dataset\n",
    "output_sequence_length = 16 # Adjust this value based on the expected number of tokens per stim_name\n",
    "embedding_dim = 32  # Dimension of the dense vectors\n",
    "# Create a Normalization layer for harmfulness_score\n",
    "harmfulness_score_normalizer = Normalization()\n",
    "\n",
    "regul=5e-5   #regularization\n",
    "def create_user_input_layers():\n",
    "    age_input = tf.keras.Input(shape=(1,), name=\"age\", dtype=tf.int32)\n",
    "    gender_input = tf.keras.Input(shape=(1,), name=\"gender\", dtype=tf.string)\n",
    "    sexuality_input = tf.keras.Input(shape=(1,), name=\"sexuality\", dtype=tf.string)\n",
    "    neurodivergent_conditions_input = tf.keras.Input(shape=(1,512) , name=\"nd_conditions_embedding\", dtype=tf.float32)\n",
    "    hobbies_embedding_input = tf.keras.Input(shape=(1,512) , name=\"hobbies_embedding\", dtype=tf.float32)\n",
    "    stimming_essentiality_score_input = tf.keras.Input(shape=(1,), name=\"stimming_essentiality_score\", dtype=tf.int32)\n",
    "    current_stims_input = tf.keras.Input(shape=(None, 512), name=\"current_stims\", dtype=tf.float32)\n",
    "    return {\n",
    "        \"age\": age_input,\n",
    "        \"gender\": gender_input,\n",
    "        \"sexuality\": sexuality_input,\n",
    "        \"nd_conditions_embedding\": neurodivergent_conditions_input,\n",
    "        \"hobbies_embedding\": hobbies_embedding_input,\n",
    "        \"stimming_essentiality_score\": stimming_essentiality_score_input,\n",
    "        \"current_stims\": current_stims_input,\n",
    "    }\n",
    "def create_stim_input_layers():\n",
    "    name_input = tf.keras.Input(shape=(1,512), name=\"name_embedding\", dtype=tf.float32)\n",
    "    description_input = tf.keras.Input(shape=(1,512), name=\"description_embedding\", dtype=tf.float32)\n",
    "    harmfulness_score_input = tf.keras.Input(shape=(1,), name=\"harmfulness_score\", dtype=tf.int32)\n",
    "    associated_conditions_hobbies_input= tf.keras.Input(shape=(2, 512), dtype=tf.float32, name=\"associated_conditions_hobbies\")\n",
    "    return {\"name_embedding\": name_input, \"description_embedding\": description_input, \"harmfulness_score\": harmfulness_score_input, \n",
    "            'associated_conditions_hobbies':associated_conditions_hobbies_input}\n",
    "\n",
    "def create_user_model(user_input_layers):\n",
    "    clip_value = 0.2\n",
    "    clip_constraint = WeightClip(clip_value)\n",
    "    # Preprocessing layers\n",
    "    age_normalized = tf.expand_dims(age_normalizer(user_input_layers[\"age\"]), -1)\n",
    "    gender_embedded = gender_lookup(user_input_layers[\"gender\"])\n",
    "    sexuality_embedded = sexuality_lookup(user_input_layers[\"sexuality\"])\n",
    "    neurodivergent_conditions_embedded = user_input_layers[\"nd_conditions_embedding\"]\n",
    "    hobbies_embedded = user_input_layers[\"hobbies_embedding\"]\n",
    "    stimming_essentiality_score_normalized = tf.expand_dims(score_normalizer(user_input_layers[\"stimming_essentiality_score\"]),-1)\n",
    "    current_stims_embeddings = user_input_layers[\"current_stims\"]\n",
    "\n",
    "    # Embedding layers\n",
    "    embedding_dim = 8\n",
    "    gender_embedding = Embedding(input_dim=len(gender_lookup.get_vocabulary()), output_dim=embedding_dim)(gender_embedded)\n",
    "    sexuality_embedding = Embedding(input_dim=len(sexuality_lookup.get_vocabulary()), output_dim=embedding_dim)(sexuality_embedded)\n",
    "    #neurodivergent_conditions_dense = Embedding(input_dim=len(nd_condition_lookup.get_vocabulary()), output_dim=embedding_dim)(neurodivergent_conditions_embedded)\n",
    "    \n",
    "    \n",
    "    # Dense layers\n",
    "    age_dense = Dense(32, kernel_initializer='random_normal',activation='swish', kernel_constraint=clip_constraint,kernel_regularizer=tf.keras.regularizers.l1(regul))(tf.reshape(age_normalized, (-1, 1)))\n",
    "    stimming_essentiality_dense = Dense(128, kernel_initializer='random_normal',kernel_regularizer=tf.keras.regularizers.l1(regul),activation='swish', kernel_constraint=clip_constraint)(tf.reshape(stimming_essentiality_score_normalized, (-1, 1)))\n",
    "\n",
    "    gender_dense = Dense(32, kernel_initializer='random_normal',activation=tf.keras.activations.selu,kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(Flatten()(gender_embedding))\n",
    "    gender_dense = tf.debugging.check_numerics(gender_dense, message=\"NaN or Inf found in gender_dense\")\n",
    "    \n",
    "    sexuality_dense = Dense(128, kernel_initializer='random_normal',activation='swish',kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(Flatten()(sexuality_embedded))\n",
    "    sexuality_dense = tf.debugging.check_numerics(sexuality_dense, message=\"NaN or Inf found in sexuality_dense\")\n",
    "    \n",
    "    #neurodivergent_conditions_pooled = GlobalAveragePooling1D()(neurodivergent_conditions_dense)\n",
    "    nd_conditions_normalizer=BatchNormalization()\n",
    "    nd_condition_dense = nd_conditions_normalizer(Dense(2048, kernel_initializer='random_normal',kernel_regularizer=tf.keras.regularizers.l1(regul),activation='swish', kernel_constraint=clip_constraint)(Flatten()(neurodivergent_conditions_embedded)))\n",
    "    nd_condition_dense = tf.debugging.check_numerics(nd_condition_dense, message=\"NaN or Inf found in nd_condition_dense\")\n",
    "    \n",
    "    hobbies_normalizer=BatchNormalization()\n",
    "    hobbies_dense = hobbies_normalizer(Dense(2048, kernel_initializer='random_normal',kernel_regularizer=tf.keras.regularizers.l1(regul),activation='swish', kernel_constraint=clip_constraint)(Flatten()(hobbies_embedded)))\n",
    "    hobbies_dense = tf.debugging.check_numerics(hobbies_dense, message=\"NaN or Inf found in hobbies_dense\")\n",
    "    \n",
    "    avg_pooled_stims = tf.reduce_mean(current_stims_embeddings, axis=1)\n",
    "    stim_normalizer=BatchNormalization()\n",
    "    current_stims_embeddings_dense = stim_normalizer(Dense(1024, kernel_initializer='random_normal',kernel_regularizer=tf.keras.regularizers.l1(regul),activation='swish', kernel_constraint=clip_constraint)(avg_pooled_stims))\n",
    "    current_stims_embeddings_dense = tf.debugging.check_numerics(current_stims_embeddings_dense, message=\"NaN or Inf found in current_stims_embeddings_dense\")\n",
    "\n",
    "    flattened_stims_dense=Flatten()(current_stims_embeddings_dense)\n",
    "\n",
    "    # Concatenate dense layers\n",
    "    concatenated = Concatenate(axis=-1)([\n",
    "        age_dense,\n",
    "        gender_dense,\n",
    "        sexuality_dense,\n",
    "        nd_condition_dense,\n",
    "        hobbies_dense,\n",
    "        stimming_essentiality_dense,\n",
    "        current_stims_embeddings_dense\n",
    "    ])\n",
    "\n",
    "    flat_embeddings = Flatten()(concatenated)\n",
    "    # User Dense layers\n",
    "    layer1_norm=BatchNormalization()\n",
    "    dense_1 = layer1_norm(Dense(8192, kernel_initializer='random_normal',activation='swish', kernel_constraint=clip_constraint,kernel_regularizer=tf.keras.regularizers.l1(regul))(flat_embeddings))\n",
    "    layer2_norm=BatchNormalization()\n",
    "    dense_2 = layer2_norm(Dense(4096, kernel_initializer='random_normal',activation='swish', kernel_constraint=clip_constraint,kernel_regularizer=tf.keras.regularizers.l1(regul))(dense_1))\n",
    "    layer3_norm=BatchNormalization()\n",
    "    dense_3 = layer3_norm(Dense(2048, kernel_initializer='random_normal',activation='swish',kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(dense_2))\n",
    "    layer4_norm=BatchNormalization()\n",
    "    dense_4 = layer4_norm(Dense(1024, kernel_initializer='random_normal',activation='swish',kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(dense_3))\n",
    "    model = tf.keras.Model(inputs=user_input_layers, outputs=dense_4, name=\"user_model\")\n",
    "    return model\n",
    "\n",
    "def create_stim_model(stim_input_layers):\n",
    "    clip_value = 0.2\n",
    "    clip_constraint = WeightClip(clip_value)\n",
    "    embedded_name = stim_input_layers[\"name_embedding\"]\n",
    "    description_embedded = stim_input_layers[\"description_embedding\"]\n",
    "\n",
    "    harmfulness_score_normalized = tf.expand_dims(harmfulness_score_normalizer(stim_input_layers[\"harmfulness_score\"]), -1)\n",
    "    associated_conditions_hobbies_embedded= stim_input_layers[\"associated_conditions_hobbies\"]\n",
    "\n",
    "    name_dense=Dense(1024, kernel_initializer='random_normal',activation='swish', kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(Flatten()(embedded_name))\n",
    "    description_dense=Dense(1024, kernel_initializer='random_normal',activation='swish', kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(Flatten()(description_embedded))\n",
    "    harmfulness_score_dense=Dense(16, kernel_initializer='random_normal',activation=tf.keras.activations.selu, kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(tf.reshape(harmfulness_score_normalized,(-1,1)))\n",
    "    avg_pooled_hobbies = tf.reduce_mean(associated_conditions_hobbies_embedded, axis=1)\n",
    "    hobby_norm=BatchNormalization()\n",
    "    associated_conditions_hobbies_embedded_dense = hobby_norm(Dense(2048, kernel_initializer='random_normal', kernel_regularizer=tf.keras.regularizers.l1(regul),activation='swish', kernel_constraint=clip_constraint)(avg_pooled_hobbies))\n",
    "    flattened_hobbies_dense = Flatten()(associated_conditions_hobbies_embedded_dense)\n",
    "\n",
    "    concatenated = Concatenate(axis=-1)([\n",
    "        name_dense,\n",
    "        description_dense,\n",
    "        harmfulness_score_dense,\n",
    "        flattened_hobbies_dense\n",
    "    ])\n",
    "    flat_embeddings = Flatten()(concatenated)\n",
    "    # Flatten and Dense layers\n",
    "    layer1_norm=BatchNormalization()\n",
    "    dense_1 = layer1_norm(Dense(8192, kernel_initializer='random_normal',activation='swish',kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(flat_embeddings))\n",
    "    layer2_norm=BatchNormalization()\n",
    "    dense_2 = layer2_norm(Dense(4096, kernel_initializer='random_normal', activation='selu',kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(dense_1))\n",
    "    layer3_norm=BatchNormalization()\n",
    "    dense_3 = layer3_norm(Dense(2048, kernel_initializer='random_normal',activation='swish', kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)(dense_2))\n",
    "    layer4_norm=BatchNormalization()\n",
    "    dense_4 = layer4_norm(Dense(1024, kernel_initializer='random_normal', kernel_regularizer=tf.keras.regularizers.l1(regul),activation='selu', kernel_constraint=clip_constraint)(dense_3))\n",
    "    return tf.keras.Model(inputs=stim_input_layers, outputs=dense_4, name=\"stim_model\")\n",
    "\n",
    "user_input_layers = create_user_input_layers()\n",
    "stim_input_layers = create_stim_input_layers()\n",
    "user_model = create_user_model( user_input_layers)\n",
    "stim_model = create_stim_model( stim_input_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e54ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "relug=5e-5\n",
    "class ScoreEstimator(tf.keras.Model):\n",
    "    def __init__(self, user_model, stim_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.stim_model = stim_model\n",
    "        self.concat_layer = Concatenate(axis=-1)\n",
    "        clip_value = 0.5\n",
    "        clip_constraint = WeightClip(clip_value)\n",
    "\n",
    "        self.dense_1a = Dense(4096, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_1b = Dense(2048, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_2a = Dense(512, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_2b = Dense(256, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_3a = Dense(128, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_3b = Dense(64, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_4a = Dense(32, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_4b = Dense(16, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_5a = Dense(8, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.dense_5b = Dense(4, activation=tf.keras.activations.selu, kernel_initializer='random_normal', kernel_regularizer=regularizers.l1(relug), kernel_constraint=clip_constraint)\n",
    "        self.output_layer = Dense(1, activation=tf.keras.activations.selu, kernel_regularizer=tf.keras.regularizers.l1(regul), kernel_constraint=clip_constraint)\n",
    "\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "        self.batch_norm4 = BatchNormalization()\n",
    "        self.batch_norm5 = BatchNormalization()\n",
    "        \n",
    "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        user_inputs, stim_inputs = inputs\n",
    "        user_output = self.user_model(user_inputs)\n",
    "        stim_output = self.stim_model(stim_inputs)\n",
    "        concatenated = self.concat_layer([user_output, stim_output])\n",
    "        dense_1a_output = self.batch_norm1(self.dense_1a(concatenated))\n",
    "        dense_1b_output = self.dense_1b(dense_1a_output)\n",
    "        dense_2a_output = self.batch_norm2(self.dense_2a(dense_1b_output))\n",
    "        dense_2b_output = self.dense_2b(dense_2a_output)\n",
    "        dense_3a_output = self.batch_norm3(self.dense_3a(dense_2b_output))\n",
    "        dense_3b_output = self.dense_3b(dense_3a_output)\n",
    "        dense_4a_output = self.batch_norm4(self.dense_4a(dense_3b_output))\n",
    "        dense_4b_output = self.dense_4b(dense_4a_output)\n",
    "        dense_5a_output = self.batch_norm5(self.dense_5a(dense_4b_output))\n",
    "        dense_5b_output = self.dense_5b(dense_5a_output)\n",
    "        output = self.output_layer(dense_5b_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbf4c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.ranking_model: tf.keras.Model = ScoreEstimator(user_model,stim_model)\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, inputs):\n",
    "      #tensor_user_inputs, tensor_stim_inputs, scores = inputs[0]\n",
    "      return self.ranking_model((inputs['user_inputs'], inputs['stim_inputs']))\n",
    "\n",
    "  def compute_loss(self, inputs, training=False) -> tf.Tensor:\n",
    "      rating_predictions = self(inputs)\n",
    "      # The task computes the loss and the metrics.\n",
    "      return self.task(labels=inputs['labels'], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01179e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x226a5f4f670>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restore to use model\n",
    "def create_recommender_model(user_input_layers, stim_input_layers):\n",
    "    user_model = create_user_model(user_input_layers)\n",
    "    stim_model = create_stim_model(stim_input_layers)\n",
    "    recommender_model = RankingModel()\n",
    "    recommender_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4))\n",
    "    return recommender_model\n",
    "user_input_layers = create_user_input_layers()\n",
    "stim_input_layers = create_stim_input_layers()\n",
    "\n",
    "# Create the model architecture\n",
    "loaded_model = create_recommender_model(user_input_layers, stim_input_layers)\n",
    "\n",
    "# Load the saved weights\n",
    "model_checkpoint = tf.train.Checkpoint(model=loaded_model)\n",
    "model_checkpoint.restore(\"stimming_recommender/weights.ckpt-1\").expect_partial()\n",
    "\n",
    "user_checkpoint=tf.train.Checkpoint(model=user_model)\n",
    "user_checkpoint.restore(\"user_model_weights/weights.ckpt\").expect_partial()\n",
    "\n",
    "stim_checkpoint=tf.train.Checkpoint(model=stim_model)\n",
    "stim_checkpoint.restore(\"stim_model_weights/weights.ckpt\").expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3efa83d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[84.297874]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Load the Universal Sentence Encoder\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "def text_embedder(text):\n",
    "    return embed(text)\n",
    "def pad_or_truncate(arr, target_shape):\n",
    "    if arr.shape[0] < target_shape[0]:\n",
    "        padding = np.zeros((target_shape[0] - arr.shape[0], target_shape[1]))\n",
    "        arr = np.vstack((arr, padding))\n",
    "    elif arr.shape[0] > target_shape[0]:\n",
    "        arr = arr[:target_shape[0], :]\n",
    "    return arr\n",
    "def create_prediction_input(user_data, stim_data):\n",
    "    user_inputs = {\n",
    "        \"age\": tf.constant([user_data[\"age\"]], dtype=tf.int32),\n",
    "        \"gender\": tf.constant([user_data[\"gender\"]], dtype=tf.string),\n",
    "        \"sexuality\": tf.constant([user_data[\"sexuality\"]], dtype=tf.string),\n",
    "        \"nd_conditions_embedding\": tf.expand_dims(tf.expand_dims(text_embedder([\" and \".join(user_data[\"neurodivergent_conditions\"])])[0], axis=0), axis=1),\n",
    "        \"hobbies_embedding\": tf.expand_dims(tf.expand_dims(text_embedder([user_data[\"hobbies\"]])[0], axis=0), axis=1),\n",
    "        \"stimming_essentiality_score\": tf.constant([user_data[\"stimming_essentiality_score\"]], dtype=tf.int32),\n",
    "        \"current_stims\": tf.expand_dims(tf.expand_dims(text_embedder([user_data[\"current_stims\"]])[0], axis=0), axis=1),\n",
    "    }\n",
    "\n",
    "    stim_inputs = {\n",
    "        \"name_embedding\": tf.expand_dims(tf.expand_dims(text_embedder([stim_data[\"name\"]])[0], axis=0), axis=1),\n",
    "        \"description_embedding\": tf.expand_dims(tf.expand_dims(text_embedder([stim_data[\"description\"]])[0], axis=0), axis=1),\n",
    "        \"harmfulness_score\": tf.constant([stim_data[\"harmfulness_score\"]], dtype=tf.int32),\n",
    "        \"associated_conditions_hobbies\": tf.expand_dims(pad_or_truncate(text_embedder(stim_data[\"associated_conditions_hobbies\"]), (2, 512)), axis=0),\n",
    "    }\n",
    "\n",
    "\n",
    "    return user_inputs, stim_inputs\n",
    "\n",
    "user_data = {\n",
    "    \"age\": 20,\n",
    "    \"gender\": \"Female\",\n",
    "    \"sexuality\": \"Bisexual\",\n",
    "    \"neurodivergent_conditions\": ['Social Anxiety Disorder', 'Depression','Epilepsy'],\n",
    "    \"hobbies\": \"Drawing, Music\",\n",
    "    \"stimming_essentiality_score\": 5,\n",
    "    \"current_stims\": \"Tapping Feet\",\n",
    "}\n",
    "\n",
    "stim_data = {\n",
    "    \"name\": \"Fidgeting hands\",\n",
    "    \"description\": \"I start tearing random bits of paper whenever I'm mindless\",\n",
    "    \"harmfulness_score\": 1,\n",
    "    \"associated_conditions_hobbies\": [\"Dyslexia\", \"Masturbation\"],\n",
    "}\n",
    "\n",
    "\n",
    "user_inputs, stim_inputs = create_prediction_input(user_data, stim_data)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = loaded_model({ 'user_inputs' : user_inputs, 'stim_inputs': stim_inputs, 'labels': 0})\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e1e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea87bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
